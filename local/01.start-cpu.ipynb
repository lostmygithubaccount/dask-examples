{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Interactive Dask Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "pip install --upgrade dask-cloudprovider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install --upgrade azureml-sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESTART YOUR KERNEL**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workspace\n",
    "\n",
    "Get the Azure ML workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Workspace.create(name='AzureML', subscription_id='6560575d-fa06-4e7d-95fb-f962e74efd7a', resource_group='cody-eastus-rg')"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "ws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "################## Creating new compute targe: dask-ct-186009 ##################\nCreating\nSucceeded\nAmlCompute wait for completion finished\n\nMinimum number of nodes requested have been provisioned\n############################## Setting up cluster ##############################\nWARNING - If 'script' has been provided here and a script file name has been specified in 'run_config', 'script' provided in ScriptRunConfig initialization will take precedence.\nWARNING - If 'arguments' has been provided here and arguments have been specified in 'run_config', 'arguments' provided in ScriptRunConfig initialization will take precedence.\n####################### Waiting for scheduler node's IP ########################\n........................................................\n\n########################### Scheduler: 10.0.0.4:8786 ###########################\n############################# Not on the same VNET #############################\n###################### Running in compute instance? False ######################\n###################### scheduler_public_ip: 52.191.87.69 #######################\n######################### scheduler_public_port: 50000 #########################\n########################### Connections established ############################\n############################# Scaling to 1 workers #############################\n############################### Scaling is done ################################\n"
    }
   ],
   "source": [
    "from dask_cloudprovider import AzureMLCluster\n",
    "\n",
    "vm_size = 'STANDARD_DS13_V2'\n",
    "timeout = 7200 \n",
    "\n",
    "cluster = AzureMLCluster(ws, vm_size=vm_size, scheduler_idle_timeout=timeout, jupyter=True, show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Run(Experiment: dask-cloudprovider,\nId: dask-cloudprovider_1598986900_3f78a326,\nType: azureml.scriptrun,\nStatus: Running)",
      "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>dask-cloudprovider</td><td>dask-cloudprovider_1598986900_3f78a326</td><td>azureml.scriptrun</td><td>Running</td><td><a href=\"https://ml.azure.com/experiments/dask-cloudprovider/runs/dask-cloudprovider_1598986900_3f78a326?wsid=/subscriptions/6560575d-fa06-4e7d-95fb-f962e74efd7a/resourcegroups/cody-eastus-rg/workspaces/AzureML\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.script_run.ScriptRun?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "cluster.run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "WARNING - If 'script' has been provided here and a script file name has been specified in 'run_config', 'script' provided in ScriptRunConfig initialization will take precedence.\n"
    }
   ],
   "source": [
    "cluster.scale(20) # need more than default quota for this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "VBox(children=(HTML(value='<h2>AzureMLCluster</h2>'), HBox(children=(HTML(value='\\n<div>\\n  <style scoped>\\n  â€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4d79dc8afec54a789f02e8557ab2d2bc"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "# print out cluster widget \n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<Client: 'tcp://10.0.0.4:8786' processes=20 threads=160, memory=1.18 TB>",
      "text/html": "<table style=\"border: 2px solid white;\">\n<tr>\n<td style=\"vertical-align: top; border: 0px solid white\">\n<h3 style=\"text-align: left;\">Client</h3>\n<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n  <li><b>Scheduler: </b>tcp://localhost:9002</li>\n  <li><b>Dashboard: </b><a href='http://localhost:9001' target='_blank'>http://localhost:9001</a></li>\n</ul>\n</td>\n<td style=\"vertical-align: top; border: 0px solid white\">\n<h3 style=\"text-align: left;\">Cluster</h3>\n<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n  <li><b>Workers: </b>20</li>\n  <li><b>Cores: </b>160</li>\n  <li><b>Memory: </b>1.18 TB</li>\n</ul>\n</td>\n</tr>\n</table>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "from dask.distributed import Client \n",
    "\n",
    "c = Client(cluster)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Help on class AzureMLCluster in module dask_cloudprovider.providers.azure.azureml:\n\nclass AzureMLCluster(distributed.deploy.cluster.Cluster)\n |  AzureMLCluster(workspace, compute_target=None, environment_definition=None, experiment_name=None, initial_node_count=None, jupyter=None, jupyter_port=None, dashboard_port=None, scheduler_port=None, scheduler_idle_timeout=None, worker_death_timeout=None, additional_ports=None, admin_username=None, admin_ssh_key=None, datastores=None, code_store=None, vnet_resource_group=None, vnet=None, subnet=None, show_output=False, telemetry_opt_out=None, asynchronous=False, **kwargs)\n |  \n |  Deploy a Dask cluster using Azure ML\n |  \n |  This creates a dask scheduler and workers on an Azure ML Compute Target.\n |  \n |  Parameters\n |  ----------\n |  workspace: azureml.core.Workspace (required)\n |      Azure ML Workspace - see https://aka.ms/azureml/workspace.\n |  \n |  vm_size: str (optional)\n |      Azure VM size to be used in the Compute Target - see https://aka.ms/azureml/vmsizes.\n |  \n |  datastores: List[str] (optional)\n |      List of Azure ML Datastores to be mounted on the headnode -\n |      see https://aka.ms/azureml/data and https://aka.ms/azureml/datastores.\n |  \n |      Defaults to ``[]``. To mount all datastores in the workspace,\n |      set to ``ws.datastores.values()``.\n |  \n |  environment_definition: azureml.core.Environment (optional)\n |      Azure ML Environment - see https://aka.ms/azureml/environments.\n |  \n |      Defaults to the \"AzureML-Dask-CPU\" or \"AzureML-Dask-GPU\" curated environment.\n |  \n |  scheduler_idle_timeout: int (optional)\n |      Number of idle seconds leading to scheduler shut down.\n |  \n |      Defaults to ``1200`` (20 minutes).\n |  \n |  experiment_name: str (optional)\n |      The name of the Azure ML Experiment used to control the cluster.\n |  \n |      Defaults to ``dask-cloudprovider``.\n |  \n |  initial_node_count: int (optional)\n |      The initial number of nodes for the Dask Cluster.\n |  \n |      Defaults to ``1``.\n |  \n |  jupyter: bool (optional)\n |      Flag to start JupyterLab session on the headnode of the cluster.\n |  \n |      Defaults to ``False``.\n |  \n |  jupyter_port: int (optional)\n |      Port on headnode to use for hosting JupyterLab session.\n |  \n |      Defaults to ``9000``.\n |  \n |  dashboard_port: int (optional)\n |      Port on headnode to use for hosting Dask dashboard.\n |  \n |      Defaults to ``9001``.\n |  \n |  scheduler_port: int (optional)\n |      Port to map the scheduler port to via SSH-tunnel if machine not on the same VNET.\n |  \n |      Defaults to ``9002``.\n |  \n |  worker_death_timeout: int (optional)\n |      Number of seconds to wait for a worker to respond before removing it.\n |  \n |      Defaults to ``30``.\n |  \n |  additional_ports: list[tuple[int, int]] (optional)\n |      Additional ports to forward. This requires a list of tuples where the first element\n |      is the port to open on the headnode while the second element is the port to map to\n |      or forward via the SSH-tunnel.\n |  \n |      Defaults to ``[]``.\n |  \n |  compute_target: azureml.core.ComputeTarget (optional)\n |      Azure ML Compute Target - see https://aka.ms/azureml/computetarget.\n |  \n |  admin_username: str (optional)\n |      Username of the admin account for the AzureML Compute.\n |      Required for runs that are not on the same VNET. Defaults to empty string.\n |      Throws Exception if machine not on the same VNET.\n |  \n |      Defaults to ``\"\"``.\n |  \n |  admin_ssh_key: str (optional)\n |      Location of the SSH secret key used when creating the AzureML Compute.\n |      The key should be passwordless if run from a Jupyter notebook.\n |      The ``id_rsa`` file needs to have 0700 permissions set.\n |      Required for runs that are not on the same VNET. Defaults to empty string.\n |      Throws Exception if machine not on the same VNET.\n |  \n |      Defaults to ``\"\"``.\n |  \n |  vnet: str (optional)\n |      Name of the virtual network.\n |  \n |  subnet: str (optional)\n |      Name of the subnet inside the virtual network ``vnet``.\n |  \n |  vnet_resource_group: str (optional)\n |      Name of the resource group where the virtual network ``vnet``\n |      is located. If not passed, but names for ``vnet`` and ``subnet`` are\n |      passed, ``vnet_resource_group`` is assigned with the name of resource\n |      group associted with ``workspace``\n |  \n |  telemetry_opt_out: bool (optional)\n |      A boolean parameter. Defaults to logging a version of AzureMLCluster\n |      with Microsoft. Set this flag to False if you do not want to share this\n |      information with Microsoft. Microsoft is not tracking anything else you\n |      do in your Dask cluster nor any other information related to your\n |      workload.\n |  \n |  asynchronous: bool (optional)\n |      Flag to run jobs asynchronously.\n |  \n |  **kwargs: dict\n |      Additional keyword arguments.\n |  \n |  Method resolution order:\n |      AzureMLCluster\n |      distributed.deploy.cluster.Cluster\n |      builtins.object\n |  \n |  Methods defined here:\n |  \n |  __init__(self, workspace, compute_target=None, environment_definition=None, experiment_name=None, initial_node_count=None, jupyter=None, jupyter_port=None, dashboard_port=None, scheduler_port=None, scheduler_idle_timeout=None, worker_death_timeout=None, additional_ports=None, admin_username=None, admin_ssh_key=None, datastores=None, code_store=None, vnet_resource_group=None, vnet=None, subnet=None, show_output=False, telemetry_opt_out=None, asynchronous=False, **kwargs)\n |      Initialize self.  See help(type(self)) for accurate signature.\n |  \n |  close(self)\n |      Close the cluster. All Azure ML Runs corresponding to the scheduler\n |      and worker processes will be completed. The Azure ML Compute Target will\n |      return to its minimum number of nodes after its idle time before scaledown.\n |  \n |  close_when_disconnect(self)\n |  \n |  scale(self, workers=1)\n |      Scale the cluster. Scales to a maximum of the workers available in the cluster.\n |  \n |  scale_down(self, workers=1)\n |      Scale down the number of workers. Scales to minimum of 1.\n |  \n |  scale_up(self, workers=1)\n |      Scale up the number of workers.\n |  \n |  ----------------------------------------------------------------------\n |  Readonly properties defined here:\n |  \n |  dashboard_link\n |      Link to Dask dashboard.\n |  \n |  jupyter_link\n |      Link to JupyterLab on running on the headnode of the cluster.\n |      Set ``jupyter=True`` when creating the ``AzureMLCluster``.\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from distributed.deploy.cluster.Cluster:\n |  \n |  async __aenter__(self)\n |  \n |  async __aexit__(self, typ, value, traceback)\n |  \n |  __del__(self)\n |  \n |  __enter__(self)\n |  \n |  __exit__(self, typ, value, traceback)\n |  \n |  __repr__(self)\n |      Return repr(self).\n |  \n |  adapt(self, Adaptive=<class 'distributed.deploy.adaptive.Adaptive'>, **kwargs) -> distributed.deploy.adaptive.Adaptive\n |      Turn on adaptivity\n |      \n |      For keyword arguments see dask.distributed.Adaptive\n |      \n |      Examples\n |      --------\n |      >>> cluster.adapt(minimum=0, maximum=10, interval='500ms')\n |  \n |  get_logs(self, cluster=True, scheduler=True, workers=True)\n |      Return logs for the cluster, scheduler and workers\n |      \n |      Parameters\n |      ----------\n |      cluster : boolean\n |          Whether or not to collect logs for the cluster manager\n |      scheduler : boolean\n |          Whether or not to collect logs for the scheduler\n |      workers : boolean or Iterable[str], optional\n |          A list of worker addresses to select.\n |          Defaults to all workers if `True` or no workers if `False`\n |      \n |      Returns\n |      -------\n |      logs: Dict[str]\n |          A dictionary of logs, with one item for the scheduler and one for\n |          each worker\n |  \n |  logs(self, *args, **kwargs)\n |  \n |  sync(self, func, *args, asynchronous=None, callback_timeout=None, **kwargs)\n |  \n |  ----------------------------------------------------------------------\n |  Readonly properties inherited from distributed.deploy.cluster.Cluster:\n |  \n |  asynchronous\n |  \n |  observed\n |  \n |  plan\n |  \n |  requested\n |  \n |  scheduler_address\n |  \n |  ----------------------------------------------------------------------\n |  Data descriptors inherited from distributed.deploy.cluster.Cluster:\n |  \n |  __dict__\n |      dictionary for instance variables (if defined)\n |  \n |  __weakref__\n |      list of weak references to the object (if defined)\n\n"
    }
   ],
   "source": [
    "help(AzureMLCluster)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('dkdc': conda)",
   "language": "python",
   "name": "python_defaultSpec_1598986412203"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}